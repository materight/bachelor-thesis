\chapter{Results}
\label{cha:results}

The first section of this chapter briefly discusses the implementation of the prototypes used for testing and for performance evaluation. The next sections present the results obtained by the forecasting techniques described in the previous chapter and justify the choices made for the final model.

\section{Prototype implementation}
\label{sec:prototype_implementation}

Different prototypes for the models presented in Chapter~\ref{cha:solution} were implemented in Python to be able to evaluate the prediction accuracy. To simplify the whole evaluation process, they were implemented and tested separately, to avoid having a model’s results influencing another’s. When the final architecture of the complete predictive model was defined by choosing the prototypes that obtained the best performances, a final implementation, with all the submodules working sequentially, was written. This implementation was designed to be able to observe the customers' behavior and produce forecasts in real-time, and to be updated with newly collected observations once a day. With this structure, the prototype can be easily ported to Scala and integrated into the RetailerIN platform without needing much refactoring.

\section{Inflow rate forecast}
\label{sec:inflow_rate_forecast_results}

This section discusses the results obtained by the forecasting methods for the inflow rate presented in Section~\ref{sec:inflow_rate_forecast}, in particular:
\begin{itemize}
  \item Persistence model
  \item Drift model
  \item Artificial Neural Network model
  \item SARIMA model
\end{itemize}

Given the greater amount of available data, the \emph{dataset A} (see Section~\ref{sec:datasets_description}) was chosen for the models' evaluation. Each model was trained on the first half (from September to November) and tested on the second half (from December to February) of the dataset.

The models’ prediction accuracy was evaluated by analyzing the \emph{one-step forecast} errors on the test set. A \emph{forecast error} is the difference between an observed value and its forecast and it can be written as \( e_t = y_t - \hat{y}_t \). Only the forecasts for the store’s opening hours (from 6:00 to 23:00) were considered on the evaluation, since the values outside these periods are equal to zero and therefore not relevant. Different measures were used to summarize the forecast errors:
\begin{itemize}
  \item \emph{Mean Absolute Error}: \( \text{MAE} = \text{mean}(| e_t |) \)
  \item \emph{Root Mean Square Error}: \( \text{RMSE} = \sqrt{\text{mean}(e_t^2)} \)
  \item \emph{Mean Absolute Percentage Error}: \( \text{MAPE} =  \text{mean}(| 100 e_t / y_t |) \)
\end{itemize}

Since the final implementation in the RetailerIN system will work in a real-time environment, the computational performances are another important aspect that must be taken in consideration when choosing the forecasting method. This metric is composed by two measurements: the \emph{forecast time} and the \emph{update time}, that respectively indicate the average times spent by the model computing the forecast for the next interval and updating the model with new collected data. The forecasting time is the most significant of the two, since new predictions are computed with high frequency, given the intervals’ short length, while the model updates are executed once every day, preferably when the store is closed. The time spent for the initial training, when the system is started for the first time, is not significant and therefore not considered.

Table~\ref{tab:inflow_rate_forecast_results} summarizes the results obtained by each model. The residuals analysis for the AR-NN model can be seen in Figure~\ref{fig:inflow_rate_forecast_residuals}.

\begin{center}
  \captionof{table}{\label{tab:inflow_rate_forecast_results}Accuracy and performance results of the inflow rate predictive models.}
  \begin{tabular}{ l r r r r }
    \hline
    Model name     & MAE             & RMSE            & MAPE               & Forecast time (ms) \\
    \hline
    Persistence    & 5.0355          & 7.1982          & 49.2727\%          & 0.0001             \\
    Drift          & 2.6586          & 3.5376          & 15.1712\%          & 0.0023             \\
    \textbf{AR-NN} & \textbf{2.6027} & \textbf{3.4878} & \textbf{14.0093\%} & \textbf{2.1529}    \\
    SARIMA         & 3.1986          & 4.2620          & 19.8370\%          & 3.3107             \\
    \hline
  \end{tabular}
\end{center}

\begin{figure}
  \begin{center}
    \inputpgf{img}{inflow_rate_forecast_residuals.pgf}
  \end{center}
  \caption{Residuals analysis of the AR-NN model.}
  \label{fig:inflow_rate_forecast_residuals}
\end{figure}

\subsection{Conclusions}
\label{subsec:inflow_rate_forecast_results_conclusions}

The best performances in terms of forecast accuracy were obtained by the AR-NN model, and the analysis of the residuals shows that there is no information left out from the approximation. However, the Drift model was chosen to be implemented in the final architecture, since it obtained very similar results and the calculation of a new forecast is faster. Moreover, the implementation of the Drift model is much simpler than a neural network, thus it can be implemented directly without needing any additional library.

\section{Arrival rate forecast}
\label{sec:arrival_rate_forecast_results}

In Section~\ref{sec:arrival_rate_forecast} a forecasting method for the arrival rate was described. To evaluate the accuracy of the aforementioned model’s forecast, a measurement of the actual arrival rate was necessary. Unfortunately this information was not directly available in neither of the two datasets, so an approximation based on the queue behavior was determined, in particular, based on the total number of customers in queue, available with one-minute frequency. When the total number of customers in queue increases, a new customer must have joined the queue. Therefore, the positive difference between consecutive intervals values should represent the number of new customers that have just arrived at the checkouts. The arrival rate \( \lambda_t \) can be then written as:
\begin{equation}
  \lambda_t = Lq_t^{TOT} - Lq_{t-1}^{TOT} + \theta_{t-1}
\end{equation}
where \( Lq_t^{TOT} \) is the total number of customers in queue at time \( t \) and \( \theta_{t-1} \) is the total number of customers served at time \( t-1 \). The obtained results were then aggregated in 10-minute intervals to obtain the same frequency as the forecast. With this approach, the \emph{dataset A} could not be used for the accuracy evaluation since it does not contain data regarding the total number of customers in queue. Instead, the evaluation was conducted over the smaller \emph{dataset B}.

Since this model is still part of the time series forecasting field, the same errors measures presented in the previous section were used. The accuracy for various multi-step forecasts is shown in the Table~\ref{tab:arrival_rate_forecast_results}. The number of steps indicates the number of future intervals forecasted, e.g. a three-step forecasting gives prediction values for \( \lambda_{t+3} \), having the measured inflow rate data till interval \( t \).

\begin{center}
  \captionof{table}{\label{tab:arrival_rate_forecast_results}Accuracy results of the arrival rate predictive model.}
  \begin{tabular}{ l r r r }
    \hline
    Steps & MAE    & RMSE   & MAPE      \\
    \hline
    1     & 1.3220 & 1.8464 & 20.4156\% \\
    2     & 1.4769 & 1.9971 & 21.8374\% \\
    3     & 1.5559 & 2.1961 & 24.2532\% \\
    4     & 1.7508 & 2.4305 & 27.0171\% \\
    \hline
  \end{tabular}
\end{center}

\subsection{Conclusions}
\label{subsec:arrival_rate_forecast_results_conclusions}

The results show that the model’s prediction accuracy decreases as the number of steps ahead for which the forecast is computed increases. This is probably caused by the error introduced by the store’s inflow rate forecast: for example, the three-step predictions are based on the one-step and two-step inflow rate’s predictions, as described in Section~\ref{sec:arrival_rate_forecast}. Therefore, improving the inflow rate forecasting model introduced previously would also increase the overall performances of this model.

Another important factor that must be taken in consideration when evaluating the results is the period in which the data have been collected. As stated in Section~\ref{sec:datasets_description}, the \emph{dataset B} used in the evaluation covers a two-month time span, from the 6th of February to the 25th of March 2020, and includes data from a store in northern Italy. In that period the COVID-19 emergency imposed various security measures that greatly affected the customers' shopping behavior and the supermarkets' traffic: limits on the number of customers in the shop at the same time, waiting queues for entering the stores and minimum safe distances. Moreover, at the beginning of the pandemic, a lot of people started panic-buying, so the traffic levels were unusually high.

A further improvement would be also given by including in the model the analysis of the customers’ movements during the shopping sessions. This would require to process in real-time the position of every customer currently in the shop, with the aim of identifying some recurrent shopping behavior that could give a forecast of the actual time that each customer will spend inside the store. This forecast could take in consideration the walking speed, the entry time, the pauses, the followed path, and any other significant information that would allow to assign each customer to a specific group of people with similar shopping behavior, and therefore with similar dwell times. The dwell times such determined would probably be much more accurate, since they would not be based only on the day and hour of the shopping session as the approximation used in this research, and would therefore improve the arrival rate forecast. However, these types of advanced analyses would require high-frequency data about the asset’s movements in each session and different forecasting techniques, that are out of the scope of this research.

\section{Queue length forecast}
\label{sec:queue_length_forecast_results}

The results obtained by the arrival rate forecast presented in the last section were used in this section to calculate a forecast of the waiting queue length. In Section~\ref{subsec:queue_length_approximation} three approximations of the average queue length based on the SBC approach were presented:
\begin{itemize}
  \item A1
  \item A2
  \item MAR
\end{itemize}

Besides the arrival rate, these models also requires an approximation of the service rate in order to be used. With the approach presented in Section~\ref{subsec:service_rate_approximation}, a realistic time-independent counters’ service rate \( \mu \) was calculated, with a value of:
\[
  \mu = 2.12 \frac{\text{customers}}{\text{interval}} = 0.21 \frac{\text{customers}}{\text{min}}
\]

To evaluate the accuracy of each method, a measurement of each counter’s queue length was needed. The RetailerIN system is capable of inferring these information from the customers’ movement in the store. However, this inference is susceptible to accuracy issues, due to the nature of the problem, that must be taken in account when evaluating the forecasting performance. These issues includes:
\begin{itemize}
  \item Tracking of baskets: when a customer is using a basket and his turn of being served has arrived, the basket is left at the beginning of the rolling belt terminal. It is therefore impossible to determine when the customer has been served and has left the queue.
  \item Customers leaving the queue: it is possible that a customer leaves the queue to get additional products that he forgot or to join a different shorter queue. This kind of behavior is difficult to correctly track and can lead to inaccurate measurements.
  \item Sensors accuracy: if the counters or the waiting queues are too close from each other, the system may have some difficulties distinguishing every distinct queue.
\end{itemize}

As stated in the previous section, the queues length data was available only for the \emph{supermarket B}, but it covered just one week of observations, from the 2th to the 8th of March, instead of two months as the sessions dataset. Again, since the training data can be seen as a time series, the same accuracy measures from the previous section were used. The results are shown in Figure~\ref{fig:queue_length_forecast} and in Table~\ref{tab:queue_length_forecast_results}.

\begin{center}
  \captionof{table}{\label{tab:queue_length_forecast_results}Accuracy results of the queue length predictive model.}
  \begin{tabular}{ l r r r }
    \hline
    Approximation & MAE    & RMSE   & MAPE      \\
    \hline
    A1            & 0.8539 & 1.6681 & 28.7874\% \\
    A2            & 0.8049 & 1.6088 & 26.5083\% \\
    MAR           & 0.4919 & 0.9646 & 19.5708\% \\
    \hline
  \end{tabular}
\end{center}

\begin{figure}
  \begin{center}
    \inputpgf{img}{queue_length_forecast.pgf}
  \end{center}
  \caption{Example of the queue length prediction results with the A1, A2 and MAR methods.}
  \label{fig:queue_length_forecast}
\end{figure}

\subsection{Conclusions}
\label{subsec:queue_length_forecast_results_conclusions}

As explained before, the accuracy of the model is greatly affected by the accuracy of the queue length measurements. Moreover, the samples used for the evaluation were limited to only one week of data and the prediction accuracy may vary considerably depending on the considered period. There is also the store’s size factor that has a significant impact on the results: with a higher traffic level, the effects of random and unpredictable queueing behavior, as well as the errors in the measurements described before, are diminished. The store used for the evaluation is small-sized, therefore the traffic levels are quite low and the accuracy is thus affected.

\medskip
\clearpage